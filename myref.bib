@article{apley2020visualizing,
  title         = {
    Visualizing the Effects of Predictor Variables in Black Box Supervised
    Learning Models
  },
  author        = {Daniel W. Apley and Jingyu Zhu},
  year          = {2020},
  journal       = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume        = {82},
  number        = {4},
  pages         = {1059--1086},
  doi           = {10.1111/rssb.12377},
  issn          = {1369-7412},
  url           = {https://doi.org/10.1111/rssb.12377},
  eprint        = {
    https://academic.oup.com/jrsssb/article-pdf/82/4/1059/49323845/jrsssb
    \_82\_4\_1059.pdf
  },
}

@article{bach2015pixel,
  title         = {
    On Pixel-Wise Explanations for Non-Linear Classifier Decisions by
    Layer-Wise Relevance Propagation
  },
  author        = {
    Wojciech {Bach, Sebastian AND Binder, Alexander AND Montavon, Gr\' egoire
    AND Klauschen, Frederick AND M{\"u}ller, Klaus-Robert AND Samek}
  },
  year          = {2015},
  journal       = {PLOS ONE},
  publisher     = {Public Library of Science},
  volume        = {10},
  number        = {7},
  pages         = {1--46},
  doi           = {10.1371/journal.pone.0130140},
  url           = {https://doi.org/10.1371/journal.pone.0130140},
}

@article{baehrens2010explain,
  title         = {How to explain individual classification decisions},
  author        = {
    David Baehrens and Timon Schroeter and Stefan Harmeling and Motoaki
    Kawanabe and Klaus Hansen and Klaus-Robert Muller
  },
  year          = {2010},
  journal       = {Journal of Machine Learning Research},
  volume        = {11},
}

@article{Berry1988generalization,
  title         = {
    A Generalization of Cohen's Kappa Agreement Measure to Interval Measurement
    and Multiple Raters
  },
  author        = {Kenneth J. Berry and Paul W. Mielke},
  year          = {1988},
  journal       = {Educational and Psychological Measurement},
  volume        = {48},
  pages         = {921--933},
  url           = {https://api.semanticscholar.org/CorpusID:120475968},
}

@book{cover1991elements,
  title         = {Elements of Information Theory},
  author        = {Thomas M. Cover and Joy A. Thomas},
  year          = {1991},
  publisher     = {Wiley-Interscience},
}

@inproceedings{craven1996extracting,
  title         = {Extracting tree-structured representations of trained networks},
  author        = {Mark W. Craven and Jude W. Shavlik},
  year          = {1996},
  booktitle     = {Advances in Neural Information Processing Systems},
  pages         = {24--30},
}

@incollection{deraedt2008probabilistic,
  title         = {Probabilistic inductive logic programming},
  author        = {Luc De Raedt and Kristian Kersting},
  year          = {2008},
  booktitle     = {Probabilistic Inductive Logic Programming},
  publisher     = {Springer-Verlag},
  pages         = {1--27},
}

@article{friedman2001greedy,
  title         = {Greedy Function Approximation: {A} Gradient Boosting Machine},
  author        = {Jerome H. Friedman},
  year          = {2001},
  journal       = {The Annals of Statistics},
  publisher     = {Institute of Mathematical Statistics},
  volume        = {29},
  number        = {5},
  pages         = {1189--1232},
  issn          = {00905364},
  url           = {http://www.jstor.org/stable/2699986},
  urldate       = {2024-02-24},
}

@misc{guidotti2018local,
  title         = {Local Rule-Based Explanations of Black Box Decision Systems},
  author        = {
    Riccardo Guidotti and Anna Monreale and Salvatore Ruggieri and Dino
    Pedreschi and Franco Turini and Fosca Giannotti
  },
  year          = {2018},
  eprint        = {1805.10820},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
}

@article{hammoudeh2024training,
  title         = {Training data influence analysis and estimation: a survey},
  author        = {Hammoudeh, Zayd and Lowd, Daniel},
  year          = {2024},
  month         = {May},
  day           = {01},
  journal       = {Machine Learning},
  volume        = {113},
  number        = {5},
  pages         = {2351--2403},
  doi           = {10.1007/s10994-023-06495-7},
  issn          = {1573-0565},
  url           = {https://doi.org/10.1007/s10994-023-06495-7},
  abstract      = {
    Good models require good training data. For overparameterized deep models,
    the causal relationship between training data and model predictions is
    increasingly opaque and poorly understood. Influence analysis partially
    demystifies training's underlying interactions by quantifying the amount
    each training instance alters the final model. Measuring the training
    data's influence exactly can be provably hard in the worst case; this has
    led to the development and use of influence estimators, which only
    approximate the true influence. This paper provides the first comprehensive
    survey of training data influence analysis and estimation. We begin by
    formalizing the various, and in places orthogonal, definitions of training
    data influence. We then organize state-of-the-art influence analysis
    methods into a taxonomy; we describe each of these methods in detail and
    compare their underlying assumptions, asymptotic complexities, and overall
    strengths and weaknesses. Finally, we propose future research directions to
    make influence analysis more useful in practice as well as more
    theoretically and empirically sound.
  },
}

@article{hu2019optimal,
  title         = {Optimal sparse decision trees},
  author        = {Xiyang Hu and Cynthia Rudin and Margo Seltzer},
  year          = {2019},
  journal       = {Advances in Neural Information Processing Systems},
  volume        = {32},
}

@inproceedings{kaufman2011leakage,
  title         = {Leakage in data mining: Formulation, detection, and avoidance},
  author        = {Sagi Kaufman and Saharon Rosset and Claudia Perlich},
  year          = {2011},
  booktitle     = {Knowledge Discovery and Data Mining (KDD)},
}

@inproceedings{kaufmann2013information,
  title         = {Information Complexity in Bandit Subset Selection},
  author        = {Emilie Kaufmann and Shivaram Kalyanakrishnan},
  year          = {2013},
  month         = {12--14 } # jun,
  booktitle     = {Proceedings of the 26th Annual Conference on Learning Theory},
  publisher     = {PMLR},
  address       = {Princeton, NJ, USA},
  series        = {Proceedings of Machine Learning Research},
  volume        = {30},
  pages         = {228--251},
  url           = {https://proceedings.mlr.press/v30/Kaufmann13.html},
  editor        = {Shai Shalev-Shwartz and Ingo Steinwart},
  pdf           = {http://proceedings.mlr.press/v30/Kaufmann13.pdf},
}

@inproceedings{koh2017understanding,
  title         = {Understanding Black-box Predictions via Influence Functions},
  author        = {Pang Wei Koh and Percy Liang},
  year          = {2017},
  month         = {06--11 Aug},
  booktitle     = {Proceedings of the 34th International Conference on Machine Learning},
  publisher     = {PMLR},
  series        = {Proceedings of Machine Learning Research},
  volume        = {70},
  pages         = {1885--1894},
  url           = {https://proceedings.mlr.press/v70/koh17a.html},
  editor        = {Precup, Doina and Teh, Yee Whye},
  pdf           = {http://proceedings.mlr.press/v70/koh17a/koh17a.pdf},
  abstract      = {
    How can we explain the predictions of a black-box model? In this paper, we
    use influence functions -- a classic technique from robust statistics -- to
    trace a model's prediction through the learning algorithm and back to its
    training data, thereby identifying training points most responsible for a
    given prediction. To scale up influence functions to modern machine
    learning settings, we develop a simple, efficient implementation that
    requires only oracle access to gradients and Hessian-vector products. We
    show that even on non-convex and non-differentiable models where the theory
    breaks down, approximations to influence functions can still provide
    valuable information. On linear models and convolutional neural networks,
    we demonstrate that influence functions are useful for multiple purposes:
    understanding model behavior, debugging models, detecting dataset errors,
    and even creating visually-indistinguishable training-set attacks.
  },
}

@inproceedings{koh2019accuracy,
  title         = {On the Accuracy of Influence Functions for Measuring Group Effects},
  author        = {Koh, Pang Wei W and Ang, Kai-Siang and Teo, Hubert and Liang, Percy S},
  year          = {2019},
  booktitle     = {Advances in Neural Information Processing Systems},
  publisher     = {Curran Associates, Inc.},
  volume        = {32},
  url           = {
    https://proceedings.neurips.cc/paper\_files/paper/2019/file/a78482ce76496fcf49085f2190e675b4-Paper.pdf
  },
  editor        = {
    H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle
    Alch\'{e}-Buc and E. Fox and R. Garnett
  },
}

@inproceedings{krause2014submodular,
  title         = {Submodular function maximization},
  author        = {Andreas Krause and Daniel Golovin},
  year          = {2014},
  booktitle     = {Tractability: Practical Approaches to Hard Problems},
  publisher     = {Cambridge University Press},
}

@inproceedings{lakkaraju2016interpretable,
  title         = {
    Interpretable decision sets: {A} joint framework for description and
    prediction
  },
  author        = {Himabindu Lakkaraju and Sebastian H. Bach and Jure Leskovec},
  year          = {2016},
  booktitle     = {
    Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge
    Discovery and Data Mining
  },
  pages         = {1675--1684},
  organization  = {ACM},
}

@article{letham2015interpretable,
  title         = {
    Interpretable classifiers using rules and Bayesian analysis: Building a
    better stroke prediction model
  },
  author        = {Benjamin Letham and Cynthia Rudin and Tyler H. McCormick and David Madigan},
  year          = {2015},
  journal       = {Annals of Applied Statistics},
}

@inproceedings{lim2009explanations,
  title         = {
    Why and why not explanations improve the intelligibility of context-aware
    intelligent systems
  },
  author        = {Benjamin Y. Lim and Anind K. Dey and Daniel Avrahami},
  year          = {2009},
  booktitle     = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  pages         = {2119--2128},
  organization  = {ACM},
}

@article{lin2020focal,
  title         = {Focal Loss for Dense Object Detection},
  author        = {
    Tsung Yi Lin and Priya Goyal and Ross Girshick and Kaiming He and Piotr
    Doll\'ar
  },
  year          = {2020},
  journal       = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume        = {42},
  number        = {2},
  pages         = {318--327},
  doi           = {10.1109/TPAMI.2018.2858826},
}

@inproceedings{lundberg2017unified,
  title         = {A Unified Approach to Interpreting Model Predictions},
  author        = {Scott M Lundberg and Su-In Lee},
  year          = {2017},
  booktitle     = {Advances in Neural Information Processing Systems},
  publisher     = {Curran Associates, Inc.},
  volume        = {30},
  editor        = {
    I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and
    S. Vishwanathan and R. Garnett
  },
}

@inproceedings{lyon2014hellinger,
  title         = {Hellinger distance trees for imbalanced streams},
  author        = {Robert J Lyon and JM Brooke and Joshua D Knowles and Benjamin W Stappers},
  year          = {2014},
  booktitle     = {2014 22nd International conference on pattern recognition},
  pages         = {1969--1974},
  organization  = {IEEE},
}

@misc{misc_adult_2,
  title         = {Adult},
  author        = {Barry Becker and Ronny Kohavi},
  year          = {1996},
  note          = {{DOI}: https://doi.org/10.24432/C5XW20},
  howpublished  = {UCI Machine Learning Repository},
}

@article{montavon2017explaining,
  title         = {
    Explaining nonlinear classification decisions with deep Taylor
    decomposition
  },
  author        = {
    Gr\'egoire Montavon and Sebastian Lapuschkin and Alexander Binder and
    Wojciech Samek and Klaus-Robert M{\"u}ller
  },
  year          = {2017},
  journal       = {Pattern Recognition},
  volume        = {65},
  pages         = {211--222},
  doi           = {https://doi.org/10.1016/j.patcog.2016.11.008},
  issn          = {0031-3203},
  url           = {https://www.sciencedirect.com/science/article/pii/S0031320316303582},
  keywords      = {
    Deep neural networks, Heatmapping, Taylor decomposition, Relevance
    propagation, Image recognition
  },
}

@inproceedings{patel2008investigating,
  title         = {
    Investigating statistical machine learning as a tool for software
    development
  },
  author        = {Kavita Patel and James Fogarty and James A. Landay and Beverly Harrison},
  year          = {2008},
  booktitle     = {Human Factors in Computing Systems (CHI)},
}

@inproceedings{pennington2014glove,
  title         = {Glove: Global vectors for word representation},
  author        = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  year          = {2014},
  booktitle     = {Empirical Methods in Natural Language Processing (EMNLP)},
  pages         = {1532--1543},
}

@misc{radulovic2023bella,
  title         = {{BELLA}: Black box model Explanations by Local Linear Approximations},
  author        = {Nedeljko Radulovic and Albert Bifet and Fabian Suchanek},
  year          = {2023},
  eprint        = {2305.11311},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
}

@inproceedings{rasouli2020explan,
  title         = {
    {EXPLAN}: Explaining Black-box Classifiers using Adaptive Neighborhood
    Generation
  },
  author        = {Peyman Rasouli and Ingrid Chieh Yu},
  year          = {2020},
  booktitle     = {2020 International Joint Conference on Neural Networks (IJCNN)},
  pages         = {1--9},
  doi           = {10.1109/IJCNN48605.2020.9206710},
  keywords      = {
    Data models;Predictive models;Analytical models;Machine learning;Neural
    networks;Training data;Decision trees;XAI;Interpretable Machine
    Learning;Perturbation-based Explanation Methods;Data Sampling
  },
}

@inproceedings{ren2015exploring,
  title         = {Exploring models and data for image question answering},
  author        = {Mengye Ren and Ryan Kiros and Richard S. Zemel},
  year          = {2015},
  booktitle     = {
    Proceedings of the 28th International Conference on Neural Information
    Processing Systems (NIPS'15)
  },
  pages         = {2953--2961},
  organization  = {MIT Press},
}

@inproceedings{ribeiro2016model,
  title         = {Model-agnostic interpretability of machine learning},
  author        = {Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
  year          = {2016},
  booktitle     = {Human Interpretability in Machine Learning workshop, ICML '16},
}

@inproceedings{ribeiro2016why,
  title         = {
    {"}Why Should {I} Trust You?{"}: Explaining the Predictions of Any
    Classifier
  },
  author        = {Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
  year          = {2016},
  booktitle     = {
    Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge
    Discovery and Data Mining
  },
  location      = {San Francisco, California, USA},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  series        = {KDD '16},
  pages         = {1135--1144},
  doi           = {10.1145/2939672.2939778},
  isbn          = {978-1-4503-4232-2},
  url           = {https://doi.org/10.1145/2939672.2939778},
  numpages      = {10},
  keywords      = {
    black box classifier, explaining machine learning, interpretable machine
    learning, interpretability
  },
}

@article{ribeiro2018anchors,
  title         = {Anchors: High-Precision Model-Agnostic Explanations},
  author        = {Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
  year          = {2018},
  month         = apr,
  journal       = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume        = {32},
  number        = {1},
  pages         = {1527--1535},
  doi           = {10.1609/aaai.v32i1.11491},
  url           = {https://ojs.aaai.org/index.php/AAAI/article/view/11491},
}

@article{robbins1951stochastic,
  title         = {A Stochastic Approximation Method},
  author        = {Herbert Robbins and Sutton Monro},
  year          = {1951},
  journal       = {The Annals of Mathematical Statistics},
  publisher     = {Institute of Mathematical Statistics},
  volume        = {22},
  number        = {3},
  pages         = {400--407},
  issn          = {00034851},
  url           = {http://www.jstor.org/stable/2236626},
  urldate       = {2024-03-18},
}

@article{samek2021explaining,
  title         = {
    Explaining Deep Neural Networks and Beyond: {A} Review of Methods and
    Applications
  },
  author        = {
    Wojciech Samek and Gr\'egoire Montavon and Sebastian Lapuschkin and
    Christopher J. Anders and Klaus-Robert M{\"u}ller
  },
  year          = {2021},
  journal       = {Proceedings of the IEEE},
  volume        = {109},
  number        = {3},
  pages         = {247--278},
  doi           = {10.1109/JPROC.2021.3060483},
  keywords      = {
    Deep learning;Systematics;Neural networks;Artificial intelligence;Machine
    learning;Unsupervised learning;Problem-solving;Best practices;Black-box
    models;deep learning;explainable artificial intelligence
    (XAI);Interpretability;model transparency;neural networks
  },
}

@inproceedings{sanchez2015towards,
  title         = {
    Towards extracting faithful and descriptive representations of latent
    variable models
  },
  author        = {Irina Sanchez and Tim Rocktaschel and Sebastian Riedel and Sameer Singh},
  year          = {2015},
  booktitle     = {
    AAAI Spring Symposium on Knowledge Representation and Reasoning (KRR):
    Integrating Symbolic and Neural Approaches
  },
}

@book{schmidt1988predicting,
  title         = {Predicting Recidivism in North Carolina, 1978 and 1980},
  author        = {Peter Schmidt and Ann D Witte},
  year          = {1988},
  publisher     = {Inter-university Consortium for Political and Social Research},
}

@inproceedings{sculley2015hidden,
  title         = {Hidden technical debt in machine learning systems},
  author        = {
    D. Sculley and Gary Holt and Daniel Golovin and Eugene Davydov and Todd
    Phillips and Dietmar Ebner and Vinay Chaudhary and Michael Young and
    Jean-Francois Crespo
  },
  year          = {2015},
  booktitle     = {Neural Information Processing Systems (NIPS)},
}

@article{strumbelj2010efficient,
  title         = {An efficient explanation of individual classifications using game theory},
  author        = {Erik Strumbelj and Igor Kononenko},
  year          = {2010},
  journal       = {Journal of Machine Learning Research},
  volume        = {11},
}

@inproceedings{stumpf2007toward,
  title         = {Toward harnessing user feedback for machine learning},
  author        = {
    Simone Stumpf and Vijay Rajaram and Ling Li and Margaret Burnett and Thomas
    Dietterich and Eileen Sullivan and Robyn Drummond and Jonathan Herlocker
  },
  year          = {2007},
  booktitle     = {
    Proceedings of the 12th International Conference on Intelligent User
    Interfaces
  },
  pages         = {82--91},
  organization  = {ACM},
}

@inproceedings{szegedy2015going,
  title         = {Going deeper with convolutions},
  author        = {
    Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and
    Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke
    and Andrew Rabinovich
  },
  year          = {2015},
  booktitle     = {Computer Vision and Pattern Recognition (CVPR)},
}

@article{tian2022comprehensive,
  title         = {
    A Comprehensive Survey on Poisoning Attacks and Countermeasures in Machine
    Learning
  },
  author        = {Tian, Zhiyi and Cui, Lei and Liang, Jie and Yu, Shui},
  year          = {2022},
  month         = {dec},
  journal       = {ACM Comput. Surv.},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  volume        = {55},
  number        = {8},
  doi           = {10.1145/3551636},
  issn          = {0360-0300},
  url           = {https://doi.org/10.1145/3551636},
  issue_date    = {August 2023},
  abstract      = {
    The prosperity of machine learning has been accompanied by increasing
    attacks on the training process. Among them, poisoning attacks have become
    an emerging threat during model training. Poisoning attacks have profound
    impacts on the target models, e.g., making them unable to converge or
    manipulating their prediction results. Moreover, the rapid development of
    recent distributed learning frameworks, especially federated learning, has
    further stimulated the development of poisoning attacks. Defending against
    poisoning attacks is challenging and urgent. However, the systematic review
    from a unified perspective remains blank. This survey provides an in-depth
    and up-to-date overview of poisoning attacks and corresponding
    countermeasures in both centralized and federated learning. We firstly
    categorize attack methods based on their goals. Secondly, we offer detailed
    analysis of the differences and connections among the attack techniques.
    Furthermore, we present countermeasures in different learning framework and
    highlight their advantages and disadvantages. Finally , we discuss the
    reasons for the feasibility of poisoning attacks and address the potential
    research directions from attacks and defenses perspectives, separately.
  },
  articleno     = {166},
  numpages      = {35},
  keywords      = {Deep learning, federated learning, poisoning attack, backdoor attack},
}

@article{tsoumakas2006multi,
  title         = {Multi-label classification: An overview},
  author        = {Grigorios Tsoumakas and Ioannis Katakis},
  year          = {2006},
  journal       = {International Journal of Data Warehousing and Mining},
  volume        = {3},
  number        = {3},
}

@article{ustun2015supersparse,
  title         = {Supersparse linear integer models for optimized medical scoring systems},
  author        = {Berk Ustun and Cynthia Rudin},
  year          = {2015},
  journal       = {Machine Learning},
}

@inproceedings{vedaldi2008quick,
  title         = {Quick shift and kernel methods for mode seeking},
  author        = {Andrea Vedaldi and Stefano Soatto},
  year          = {2008},
  booktitle     = {European Conference on Computer Vision},
  pages         = {705--718},
  organization  = {Springer},
}

@inproceedings{vinyals2015grammar,
  title         = {Grammar as a foreign language},
  author        = {
    Oriol Vinyals and Lukasz Kaiser and Terry Koo and Slav Petrov and Ilya
    Sutskever and Geoffrey E. Hinton
  },
  year          = {2015},
  booktitle     = {
    Advances in Neural Information Processing Systems 28: Annual Conference on
    Neural Information Processing Systems 2015
  },
  pages         = {2773--2781},
}

@inproceedings{wang2015falling,
  title         = {Falling rule lists},
  author        = {Fei Wang and Cynthia Rudin},
  year          = {2015},
  booktitle     = {Artificial Intelligence and Statistics (AISTATS)},
}

@inproceedings{wang2015or,
  title         = {
    Or's of and's for interpretable classification, with application to
    context-aware recommender systems
  },
  author        = {
    Tong Wang and Cynthia Rudin and Finale Doshi-Velez and Yimin Liu and Erica
    Klampfl and Paul MacNeille
  },
  year          = {2015},
  booktitle     = {arXiv:1504.07614},
}

@inproceedings{wieting2015towards,
  title         = {Towards universal paraphrastic sentence embeddings},
  author        = {John Wieting and Mohit Bansal and Kevin Gimpel and Karen Livescu},
  year          = {2015},
  booktitle     = {CoRR abs/1511.08198},
}

@inproceedings{xin2022exploring,
  title         = {Exploring the Whole Rashomon Set of Sparse Decision Trees},
  author        = {
    Xin, Rui and Zhong, Chudi and Chen, Zhi and Takagi, Takuya and Seltzer,
    Margo and Rudin, Cynthia
  },
  year          = {2022},
  booktitle     = {Advances in Neural Information Processing Systems},
  publisher     = {Curran Associates, Inc.},
  volume        = {35},
  pages         = {14071--14084},
  url           = {
    https://proceedings.neurips.cc/paper\_files/paper/2022/file/5afaa8b4dd18eb1eed055d2d821b58ae-Paper-Conference.pdf
  },
  editor        = {
    S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A.
    Oh
  },
}

@inproceedings{zhu2016visual7w,
  title         = {Visual7{W}: Grounded Question Answering in Images},
  author        = {Yuke Zhu and Oliver Groth and Michael Bernstein and Li Fei-Fei},
  year          = {2016},
  booktitle     = {IEEE Conference on Computer Vision and Pattern Recognition},
}
